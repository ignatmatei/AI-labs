{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CLd24Gc0Qoz"
   },
   "source": [
    "# Arbori de decizie. Păduri aleatoare\n",
    "* Tudor Berariu - 2016\n",
    "* George Muraru - 2020\n",
    "* Florin Dumitrescu - 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxigVMh10QsL"
   },
   "source": [
    "## Scopul laboratorului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CycSr6E4ltrs"
   },
   "source": [
    "Scopul acestui laborator îl reprezintă înțelegerea și implementarea arborilor de decizie a pădurilor de arbori aleatori.\n",
    "\n",
    "În prima parte a laboratorului veți implementa un arbore de decizie folosind algoritmul ID3 pentru construirea arborelui și măsurarea entropiei pentru alegerea atributului care oferă cel mai mare câștig informațional.\n",
    "\n",
    "În a doua parte a laboratorului veți implementa un clasificator de tip pădure de arbori aleatori, care va fi comparat\n",
    " cu un arbore de decizie simplu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YWxF81W1jlU"
   },
   "source": [
    "## Problema de rezolvat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3RQxoc61nrD"
   },
   "source": [
    "Problema de rezolvat ı̂n acest laborator este una de ı̂nvățare supervizată: fiind dat un **set de date X** ce conține exemple descrise printr-un set de **atribute discrete A** și etichetate cu **câte o clasă dintr-o mulțime cunoscută C**, să se construiască un model pentru clasificarea exemplelor noi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQvktw_WbZpk"
   },
   "source": [
    "### Păduri de arbori aleatori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imU3HcNzl13s"
   },
   "source": [
    "*Pădurile de arbori aleatori* (eng. Random Forest) este un model format din mai mulți arbori de decizie.\n",
    "\n",
    "Se bazează pe 2 hiperparametrii:\n",
    "* Eșantionare aleatoare din setul de date de antrenament\n",
    "* Subseturi aleatoare de atribute considerate la împărțirea pe mai multi subarbori\n",
    "\n",
    "Predicția, utilizând un astfel de model, se bazează pe clasa majoritară oferită de predicțiile indepente ale tuturor arborilor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seturi de date folosite\n",
    "\n",
    "Pentru acest laborator vom folosi urmatoarele seturi de date pentru antrenarea și testarea algoritmilor \n",
    "implementați:\n",
    "* [Car Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)\n",
    "* [Tennis](https://www.kaggle.com/fredericobreno/play-tennis)\n",
    "* [Chess](https://archive.ics.uci.edu/dataset/22/chess+king+rook+vs+king+pawn)\n",
    "\n",
    "Seturile de date sunt disponibile în folderul `datasets` sub forma unor fișiere cu extensia `.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car Evaluation\n",
    "\n",
    "Setul de date *Car Evaluation* conține informații despre caracteristicile unui autovehicul și clasa de evaluare a acestuia. Atributele sunt următoarele:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Nume atribut | Valori atribut           | Explicație                 |\n",
    "|--------------|--------------------------|----------------------------|\n",
    "| buying       | v-high, high, med, low   | prețul de cumpărare        |\n",
    "| maint        | v-high, high, med, low   | costul întreținerii        |\n",
    "| doors        | 2, 3, 4, 5-more          | numărul de uși             |\n",
    "| persons      | 2, 4, more               | capacitatea de transport   |\n",
    "| lug_boot     | small, med, big          | dimensiunea portbagajului  |\n",
    "| safety       | low, med, high           | nivelul de siguranță       |\n",
    "\n",
    "\n",
    "Clasa pe care trebuie să o prezicem este `class` și poate avea următoarele valori: \n",
    "  * `unacc`\n",
    "  * `acc`\n",
    "  * `good`\n",
    "  * `v-good`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tennis\n",
    "Setul de date *Tennis* conține informații despre caracteristicile unei zile și dacă se poate juca tenis sau nu. Atributele sunt următoarele:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Nume atribut | Valori atribut        |\n",
    "|--------------|-----------------------|\n",
    "| Outlook      | sunny, overcast, rain |\n",
    "| Temperature  | hot, mild, cool       |\n",
    "| Humidity     | high, normal          |\n",
    "| Windy        | true, false           |\n",
    "\n",
    "Clasa pe care trebuie să o prezicem este `Play` și poate avea următoarele valori:\n",
    "  * `yes`\n",
    "  * `no`\n",
    "#### Chess\n",
    "Setul de date *Chess* conține informații despre o poziție de șah și dacă jucătorul care a făcut ultima mutare a câștigat sau nu. Nu se va intra în detalii despre semnificația atributelor setului de date, acestea fiind folosite doar pentru a exemplifica construcția unui arbore de decizie.\n",
    "Atributele sunt următoarele:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Attribute Name | Possible Values | Attribute Name | Possible Values |\n",
    "|----------------|-----------------|----------------|-----------------|\n",
    "| bkblk          | f, t            | bknwy          | f, t            |\n",
    "| bkon8          | f, t            | bkona          | f, t            |\n",
    "| bkspr          | t, f            | bkxbq          | f, t            |\n",
    "| bkxcr          | t, f            | bkxwp          | t, f            |\n",
    "| blxwp          | t, f            | bxqsq          | f, t            |\n",
    "| cntxt          | f, t            | dsopp          | f, t            |\n",
    "| dwipd          | l, g            | hdchk          | f, t            |\n",
    "| katri          | n, w, b         | mulch          | f, t            |\n",
    "| qxmsq          | f, t            | r2ar8          | f, t            |\n",
    "| reskd          | f, t            | reskr          | f, t            |\n",
    "| rimmx          | f, t            | rkxwp          | f, t            |\n",
    "| rxmsq          | f, t            | simpl          | t, f            |\n",
    "| skach          | f, t            | skewr          | t, f            |\n",
    "| skrxp          | f, t            | spcop          | f, t            |\n",
    "| stlmt          | f, t            | thrsk          | f, t            |\n",
    "| wkcti          | f, t            | wkna8          | f, t            |\n",
    "| wknck          | f, t            | wkovl          | t, f            |\n",
    "| wkpos          | t, f            | wtoeg          | n, t            |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Clasa pe care trebuie să o prezicem este `class` și poate avea următoarele valori:\n",
    "  * `won`\n",
    "  * `nowin`\n",
    "  \n",
    "##### Atenție!\n",
    "Nu este indicată utilizarea acestui set de date decât pentru evaluarea performanței algoritmilor implementați. Acesta este un set de date complex, cu multe atribute, care este mai greu de interpretat în momentul construirii arborelui de decizie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQvzJhiWfzm9"
   },
   "source": [
    "## Câteva biblioteci de care vom avea nevoie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomentați următoarele linii dacă nu aveți deja instalate bibliotecile\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install tqdm\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2lKg7o7nZxo"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations  # Necesar pentru a folosi tipul clasei în definiția ei\n",
    "from typing import Optional, Dict, Callable\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd  # Pentru a citi si afisa datele\n",
    "import numpy as np\n",
    "from graphviz import Digraph, Source  # Pentru a vizualiza arborele de decizie\n",
    "from IPython.display import display as idisplay  # Pentru a afisa arborele de decizie direct în celulă\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scurtă introducere în biblioteca pandas\n",
    "\n",
    "Pentru a citi datele dintr-un fișier `.csv` vom folosi biblioteca `pandas`. Aceasta oferă o structură de date tabulară numită `DataFrame` care ne permite să lucrăm cu datele într-un mod simplu și eficient. Pentru a citi datele dintr-un fișier `.csv` vom folosi funcția `pd.read_csv()`.\n",
    "\n",
    "Un `DataFrame` este o structură de date bidimensională, cu date organizate în coloane, care pot avea tipuri de date diferite. Fiecare coloană sau rând dintr-un `DataFrame` este un obiect de tip `pd.Series`, care este un vector unidimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25  Cluj-Napoca\n",
      "1      Bob   30    București\n",
      "2  Charlie   35         Iași\n",
      "3    David   40    Timișoara\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de creare a unui DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'City': ['Cluj-Napoca', 'București', 'Iași', 'Timișoara']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aceasta va afișa:\n",
    "\n",
    "```\n",
    "      Name  Age         City\n",
    "0    Alice   25  Cluj-Napoca\n",
    "1      Bob   30    București\n",
    "2  Charlie   35         Iași\n",
    "3    David   40   Timișoara\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a accesa o coloană dintr-un `DataFrame` putem folosi `df['NumeColoană']` sau `df.NumeColoană`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a unei coloane dintr-un DataFrame folosind df['NumeColoană']\n",
    "print(df['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a unei coloane dintr-un DataFrame folosind df.NumeColoană\n",
    "print(df.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coloana `df['Name']` va fi un obiect de tip `pd.Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a accesa o linie dintr-un `DataFrame` putem folosi `df.iloc[linie]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Alice\n",
      "Age              25\n",
      "City    Cluj-Napoca\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a unei linii dintr-un DataFrame folosind df.iloc[linie]\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linia `df.iloc[0]` va fi un obiect de tip `pd.Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferența dintre un obiect de tip `pd.Series` și un obiect de tip `pd.DataFrame` este că un `pd.Series` este un vector unidimensional, în timp ce un `pd.DataFrame` este o structură de date bidimensională. Pentru a accesa un element dintr-un `pd.Series` putem folosi `pd.Series[index]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a unui element dintr-un pd.Series folosind pd.Series[index]\n",
    "df_name_series = df['Name']\n",
    "print(df_name_series[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog, pentru a accesa un element dintr-un `pd.DataFrame` putem folosi mai multe metode:\n",
    "* `df[coloană][linie]`\n",
    "* `df.loc[linie, coloană]`\n",
    "* `df.iloc[linie, coloană]`\n",
    "\n",
    "Diferența dintre `df.loc[linie, coloană]` și `df.iloc[linie, coloană]` este că `df.loc[linie, coloană]` folosește numele coloanelor, în timp ce `df.iloc[linie, coloană]` folosește indicii numerici ai coloanelor.\n",
    "\n",
    "**Întrebare**: Ce se întâmplă dacă folosim `df[coloană, linie]`?\n",
    "\n",
    "Se va arunca o excepție de tip `KeyError` deoarece `df[coloană, linie]` nu este o metodă validă de accesare a unui element dintr-un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['Name'][0] ='Alice'\n",
      "df.loc[0, 'Name'] ='Alice'\n",
      "df.iloc[0, 0] ='Alice'\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a unui element dintr-un DataFrame\n",
    "print(f\"{df['Name'][0] =}\")\n",
    "print(f\"{df.loc[0, 'Name'] =}\")\n",
    "print(f\"{df.iloc[0, 0] =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accesarea mai multor linii sau coloane dintr-un `DataFrame` se poate face folosind `df.loc[linie_start:linie_stop, coloană_start:coloană_stop]` sau `df.iloc[linie_start:linie_stop, coloană_start:coloană_stop]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de accesare a mai multor linii sau coloane dintr-un DataFrame\n",
    "print(df.loc[0:2, 'Name':'Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a extrage doar valorile care corespund unei condiții putem folosi `df[df['NumeColoană'] == valoare]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age       City\n",
      "2  Charlie   35       Iași\n",
      "3    David   40  Timișoara\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de extragere a valorilor care corespund unei condiții dintr-un DataFrame\n",
    "print(df[df['Age'] > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog, putem obține doar valorile care corespund mai multor condiții folosind `df[(df['NumeColoană1'] == valoare1) & (df['NumeColoană2'] == valoare2)]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "3  David   40  Timișoara\n"
     ]
    }
   ],
   "source": [
    "# Exemplu de extragere a valorilor care corespund mai multor condiții dintr-un DataFrame\n",
    "print(df[(df['Age'] > 30) & (df['City'] == 'Timișoara')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O altă funcționalitate utilă a bibliotecii a folosirii obiectelor de tip `DataFrame` sau `Series` este că acestea ne oferă metode prin care să putem compara 2 vectori și să returnăm doar acele intrări (rânduri) care sunt comune între cei doi vectori. Această funcționalitate este utilă când dorim să calculăm metricile de evaluare ale unui model de clasificare, putând compara predicțiile modelului cu etichetele reale ale setului de date. În mod implicit se păstrează indexul rândurilor care sunt identice între cei doi vectori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "4    e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Definim 2 obiecte de tip Series\n",
    "y_true = pd.Series(['a', 'b', 'd', 'd', 'e'])\n",
    "y_pred = pd.Series(['a', 'b', 'c', 'f', 'e'])\n",
    "\n",
    "# Obținem doar valorile care sunt prezente în ambele obiecte\n",
    "common_values = y_true[y_true == y_pred]\n",
    "print(common_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVVLxc0geBix"
   },
   "source": [
    "## Definirea constantelor și a hiperparametrilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTGgZTdXeHaS"
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = 'res-id3'  # directorul în care se află seturile de date\n",
    "DATASET_NAME = 'tennis'    # @param ['car', 'tennis', 'chess']\n",
    "\n",
    "# Adâncimea maxima a arborilor\n",
    "MAX_DEPTH = 3 #@param {type: \"slider\", min: 1, max: 9999}\n",
    "\n",
    "# Procentul de exemple din setul de date utilizat la construcția arborilor\n",
    "MIN_SAMPLES_PER_NODE = 2  #@param {type: \"slider\", min: 2, max: 100}\n",
    "\n",
    "# Numele atributului care reprezintă clasa\n",
    "if DATASET_NAME in ['car', 'chess']:\n",
    "    TARGET_FEATURE = 'class'\n",
    "elif DATASET_NAME == 'tennis':\n",
    "    TARGET_FEATURE = 'Play'\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset {DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seturi de date\n",
    "\n",
    "Seturile de date folosite sunt disponibile în folderul `datasets` sub forma unor fișiere cu extensia `.csv`. Acestea \n",
    "sunt citite și încărcate în memorie folosind biblioteca `pandas`, care oferă o structură de date tabulară numită \n",
    "`DataFrame`.\n",
    "\n",
    "Din punct de vedere al notației, setul de date este reprezentat astfel:\n",
    "* $X$ &rarr; atributele setului de date, reprezentate sub forma unui tabel cu $n$ linii și $m$ coloane, unde $n$ reprezintă numărul de exemple, iar $m$ numărul de atribute\n",
    "* $y$ &rarr; clasele (etichetele) setului de date, reprezentate sub forma unui vector cu $n$ elemente, unde $n$ reprezintă numărul de exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Incarca in memorie un set de date\n",
    "    \n",
    "    Args:\n",
    "        dataset_filename (str): \n",
    "            Numele fisierului ce contine setul de date (cu tot cu extensie)\n",
    "     \n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            Un DataFrame pandas ce contine setul de date\n",
    "    \"\"\"\n",
    "    print (f\"Dataset: {dataset_filename}\")\n",
    "\n",
    "    dataset_path = Path(DATASET_ROOT) / dataset_filename\n",
    "    \n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset {dataset_filename} not found at {dataset_path}\")\n",
    "    return pd.read_csv(dataset_path)\n",
    "\n",
    "def display_dataset(dataset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Afiseaza primele 5 intrări din setul de date\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): \n",
    "            Setul de date in format pandas DataFrame.\n",
    "    \"\"\"\n",
    "    print(dataset.head(n=5))\n",
    "    \n",
    "def display_dataset_feature_values(dataset: pd.DataFrame, feature: str):\n",
    "    \"\"\"\n",
    "    Afiseaza valorile distincte ale unui atribut din setul de date\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame):\n",
    "            Setul de date in format pandas DataFrame.\n",
    "        feature (str):\n",
    "            Numele atributului pentru care se vor afisa valorile distincte.\n",
    "    \"\"\"\n",
    "    print(dataset[feature].unique())\n",
    "    \n",
    "def split_dataset(dataset: pd.DataFrame, target_feature: str) -> (pd.DataFrame, pd.Series):\n",
    "    \"\"\"\n",
    "    Imparte setul de date in atribute si clase (etichete). In cazul seturilor noastre de date, ultima coloana reprezinta intotdeauna clasa.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): \n",
    "            Setul de date in format pandas DataFrame.\n",
    "        target_feature (str): \n",
    "            Numele atributului care reprezinta clasa.\n",
    "        \n",
    "    Returns:\n",
    "        tuple(pd.DataFrame, pd.Series): \n",
    "            Un tuplu ce contine atributele si clasele setului de date in formatul (X, y)\n",
    "    \"\"\"    \n",
    "    return dataset.drop(columns=[target_feature]), dataset[target_feature]\n",
    "\n",
    "def split_train_test(dataset: pd.DataFrame, \n",
    "                     target_feature: str, \n",
    "                     test_size: float = 0.2) -> (pd.DataFrame, pd.Series, \n",
    "                                                 pd.DataFrame, pd.Series):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a training set and a testing set.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): \n",
    "            Setul de date in format pandas DataFrame.\n",
    "        target_feature (str): \n",
    "            Numle atributului care reprezinta clasa.\n",
    "        test_size (float, optional): \n",
    "            Proportia setului de date care va fi folosita pentru testare. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        tuple(pd.DataFrame, pd.Series, pd.DataFrame, pd.Series): \n",
    "            Un tuplu ce contine atributele si clasele setului de date de antrenare si de testare in formatul \n",
    "            (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Imparte setul de date in set de antrenare si set de testare\n",
    "    train_set, test_set = train_test_split(dataset, test_size=test_size, shuffle=True)\n",
    "    \n",
    "    # Imparte setul de date in atribute si clase\n",
    "    X_train_, y_train_ = split_dataset(train_set, target_feature)\n",
    "    X_test_, y_test_ = split_dataset(test_set, target_feature)\n",
    "\n",
    "    return X_train_, y_train_, X_test_, y_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregătire set de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: tennis\n",
      "    Outlook Temperature Humidity  Windy Play\n",
      "0     sunny         hot     high  False   no\n",
      "1     sunny         hot     high   True   no\n",
      "2  overcast         hot     high  False  yes\n",
      "3      rain        mild     high  False  yes\n",
      "4      rain        cool   normal  False  yes\n"
     ]
    }
   ],
   "source": [
    "# Se incarca setul de date si se afiseaza primele 5 inregistrari\n",
    "data = load_dataset(DATASET_NAME)\n",
    "display_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "\t['no' 'yes']\n",
      "Attribute: Outlook\n",
      "\t['sunny' 'overcast' 'rain']\n",
      "Attribute: Temperature\n",
      "\t['hot' 'mild' 'cool']\n",
      "Attribute: Humidity\n",
      "\t['high' 'normal']\n",
      "Attribute: Windy\n",
      "\t[False  True]\n",
      "Attribute: Play\n",
      "\t['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Se afiseaza clasele distincte ale setului de date\n",
    "print(\"Classes: \", end=\"\\n\\t\")\n",
    "display_dataset_feature_values(data, TARGET_FEATURE)\n",
    "\n",
    "# Se afiseaza valorile distincte ale fiecarui atribut din setul de date\n",
    "for feature_name in data.columns:\n",
    "    print(f\"Attribute: {feature_name}\", end=\"\\n\\t\")\n",
    "    display_dataset_feature_values(data, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setul de antrenare conține 11 exemple\n",
      "Setul de testare conține 3 exemple\n"
     ]
    }
   ],
   "source": [
    "# Se imparte setul de date in set de date de antrenare si set de date de testare\n",
    "X_train, y_train, X_test, y_test = split_train_test(data, target_feature=TARGET_FEATURE)\n",
    "\n",
    "print(f\"Setul de antrenare conține {len(X_train)} exemple\")\n",
    "print(f\"Setul de testare conține {len(X_test)} exemple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyJFPSkseHlf"
   },
   "source": [
    "## Arbore de decizie\n",
    "\n",
    "Un arbore de decizie este un clasificator ce aproximează funcții discrete.\n",
    "\n",
    "Într-un arbore de decizie există 2 tipuri de noduri:\n",
    "* *noduri intermediare* - conține un test pentru un atribut și are câte un arc (și implicit un subarbore) pentru fiecare valoare posibiliă a atributului\n",
    "* *noduri frunză* - este etichetat cu o clasă\n",
    "\n",
    "Pentru **a clasifica un obiect nou** se pornește din rădăcina arborelui și din fiecare nod se coboară pe arcul corespunzător valorii atributului pe care o are obiectul dat. Atunci când se ajunge ı̂ntr-un nod frunză, clasa acestuia va reprezenta predicția arborelui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    \"\"\"\n",
    "    Un nod din arborele de decizie. Acesta poate fi un nod intermediar sau un nod frunză.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 feature: Optional[str] = None, \n",
    "                 children: Optional[Dict[str, DecisionTreeNode]] = None, \n",
    "                 label: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Constructor pentru un nod din arborele de decizie\n",
    "        \n",
    "        Args:\n",
    "            feature (str, optional): \n",
    "                Numele atributului după care se face împărțirea. Defaults to None.\n",
    "            children (Dict[str, DecisionTreeNode], optional): \n",
    "                Un dictionar ce conține subarborii nodului curent. Defaults to None.\n",
    "            label (str, optional): \n",
    "                Clasa nodului frunză. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.split_feature = feature  # Numele atributului după care se face împărțirea (None pentru nodurile frunză)\n",
    "        self.children = children if (children is not None and feature is not None) else {}\n",
    "        self.label = label    # Clasa nodului frunză (None pentru nodurile intermediare)\n",
    "        self.depth = 1        # Adâncimea nodului în arbore (se calculează în timpul construcției arborelui)\n",
    "        self.score = 0        # Scorul nodului (se calculează în timpul construcției arborelui)\n",
    "        self.num_samples = 0  # Numărul de exemple din setul de date care ajung în nodul curent\n",
    "    \n",
    "    def get_tree_graph(self,\n",
    "                       graph: Digraph = None) -> Digraph:\n",
    "        \"\"\"\n",
    "        Construiește reprezentarea grafică a arborelui de decizie folosind biblioteca Graphviz\n",
    "    \n",
    "        Args:\n",
    "            graph (Digraph, optional): \n",
    "                Obiectul Digraph în care se construiește reprezentarea arborelui. Defaults to None.\n",
    "        \"\"\"\n",
    "        if graph is None:\n",
    "            graph = Digraph()\n",
    "            graph.attr('node', shape='box')\n",
    "    \n",
    "        if self.split_feature is None:\n",
    "            # Nod frunză\n",
    "            graph.node(f\"{self}\", f\"Label: {self.label}\\n\"\n",
    "                                  f\"Score: {self.score:.3f}\\n\"\n",
    "                                  f\"Samples: {self.num_samples}\", \n",
    "                       fillcolor='darkolivegreen2', style='filled')\n",
    "        else:\n",
    "            # Nod intermediar\n",
    "            graph.node(f\"{self}\", f\"Split: {self.split_feature}?\\n\"\n",
    "                                  f\"Score: {self.score:.3f}\\n\"\n",
    "                                  f\"Samples: {self.num_samples}\", fillcolor='lightblue', style='filled')\n",
    "            \n",
    "            for value, child in self.children.items():\n",
    "                child.get_tree_graph(graph)\n",
    "                graph.edge(f\"{self}\", f\"{child}\", label=f\"{value}\")\n",
    "    \n",
    "        return graph\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Afișează arborele de decizie folosind biblioteca Graphviz. Arborele va fi afișat ca output al celulei.\n",
    "        \"\"\"\n",
    "        graph = self.get_tree_graph()\n",
    "        idisplay(Source(graph.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplu de utilizare a clasei DecisionTreeNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"424pt\" height=\"294pt\"\n",
       " viewBox=\"0.00 0.00 424.00 293.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 289.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-289.75 420,-289.75 420,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598c4d0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598c4d0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"237.88,-285.75 116.12,-285.75 116.12,-226 237.88,-226 237.88,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc6570680 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc6570680</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"106,-172.75 0,-172.75 0,-113 106,-113 106,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: No</text>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6570680 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6570680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.42,-225.71C129.02,-211.93 110.47,-195.32 94.12,-180.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.71,-178.3 86.92,-174.24 92.04,-183.52 96.71,-178.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.92\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">Sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc5ffca70 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc5ffca70</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"230,-172.75 124,-172.75 124,-113 230,-113 230,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: Yes</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc5ffca70 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc5ffca70</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177,-225.71C177,-213.07 177,-198.04 177,-184.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.5,-184.74 177,-174.74 173.5,-184.74 180.5,-184.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.88\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">Overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598cef0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598cef0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"354,-172.75 248,-172.75 248,-113 354,-113 354,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Wind?</text>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc598cef0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598c4d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc598cef0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.82,-225.63C230.48,-220.09 238.15,-214.11 245,-208 253.94,-200.02 262.84,-190.67 270.82,-181.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"273.32,-184.07 277.18,-174.21 268.01,-179.51 273.32,-184.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.79\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">Rain</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc6064260 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc6064260</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"292,-59.75 186,-59.75 186,0 292,0 292,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: Yes</text>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598cef0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6064260 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598cef0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6064260</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.71,-112.71C277.43,-99.69 268.75,-84.14 260.92,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.07,-68.57 256.13,-61.55 257.96,-71.99 264.07,-68.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.84\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">Weak</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc6066870 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc6066870</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"416,-59.75 310,-59.75 310,0 416,0 416,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: No</text>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 0</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc598cef0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6066870 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc598cef0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc6066870</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.29,-112.71C324.57,-99.69 333.25,-84.14 341.08,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.04,-71.99 345.87,-61.55 337.93,-68.57 344.04,-71.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.09\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">Strong</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc6ba6ff0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se creează rădăcina arborelui, care are ca atribut de împărțire \"Outlook\"\n",
    "root = DecisionTreeNode(feature=\"Outlook\")\n",
    "\n",
    "# Se adaugă subarborii rădăcinii\n",
    "root.children = {\n",
    "    \"Sunny\": DecisionTreeNode(label=\"No\"),\n",
    "    \"Overcast\": DecisionTreeNode(label=\"Yes\"),\n",
    "    \"Rain\": DecisionTreeNode(feature=\"Wind\")\n",
    "}\n",
    "\n",
    "# Se adaugă subarborii nodului corespunzător valorii \"Rain\"\n",
    "root.children[\"Rain\"].children = {\n",
    "    \"Weak\": DecisionTreeNode(label=\"Yes\"),\n",
    "    \"Strong\": DecisionTreeNode(label=\"No\")\n",
    "}\n",
    "\n",
    "# Se afișează arborele de decizie\n",
    "root.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construirea arborelui de decizie\n",
    "\n",
    "* Dacă toate exemplele din $X$ aparțin unei singure clasă $C$, atunci se construiește un nod frunză etichetat cu acea clasă $C$\n",
    "* Dacă nu mai există atribute sau s-a îndeplinit un criteriu de oprire, atunci construiește nodul frunză etichetat cu cea mai frecventă clasă din $X$\n",
    "* În caz contrar:\n",
    "  * Se alege atributul $a^*$ din lista de atribute $A$ care încă nu a fost folosit (conform unui criteriu de \n",
    "  selecție) \n",
    "  * Pentru fiecare valoare posibilă $v_j$ a lui $a^*$ se construiește un subarbore:\n",
    "    * Se construiește submulțimea de exemple $X_{i/j}$ care au valoarea $v_j$ pentru atributul $a^*$: \n",
    "        $X_{i/j} = \\{x \\in X|a_{i}(x) = v_j\\}$\n",
    "    * Se construiește submulțimea de atribute $A_{new}$ care nu mai conține atributul $a^*$:  $A_{new} = A \\setminus \\{a_i\\}$\n",
    "    * Se apelează recursiv funcția de construire a arborelui pentru submulțimea de exemple $X_{i/j}$ și submulțimea de atribute $A_{new}$\n",
    "    * Se adaugă subarborele construit la nodul curent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iU0xmCIFr-fi"
   },
   "source": [
    "#### Random Tree\n",
    "\n",
    "Algoritmul Random Tree este un mod simplu de a construi un arbore de decizie. În acest caz, la fiecare pas se alege \n",
    "aleator un atribut după care se face împărțirea:\n",
    "\n",
    "$$ a^* = random\\_choice(A) $$\n",
    "\n",
    "#### Algoritmul ID3\n",
    "\n",
    "Algoritmul ID3 (Iterative Dichotomiser 3) este un algoritm folosit pentru construirea arborilor de decizie prin \n",
    "alegerea atributului care oferă cel mai mare câștig informațional la fiecare pas.\n",
    " \n",
    "Formula de calcul a câștigului informațional este dată de:\n",
    "\n",
    "  $$\n",
    "    entropy(X) = -\\sum_{c \\in C}\\frac{|X_c|}{|X|}log_2\\frac{|X_c|}{|X|}\n",
    "  $$\n",
    "  $$\n",
    "    gain(X, a_i) = entropy(X) - \\sum_{v_{j} \\in vals(a_i)} \\frac{|X_{i/j}|}{|X|}entropy(X_{i/j})\n",
    "  $$\n",
    "  $$\n",
    "    a^* = \\underset{a_i \\in A}{\\operatorname{arg max}}\\ gain(X, a_i)\n",
    "  $$\n",
    "\n",
    "În cazul prezentat mai sus, entropia este utilizată pentru a măsura randomness-ul din date. Intuitiv, cu cât un eveniment are probabilitate mai mare să se întâmple atunci acesta va avea o entropia din ce în ce mai mică. Prin modul în care se construiește arborele *ID3* se încearcă reducerea entropiei alegând la fiecare pas atributele care ne ofera cea mai multă informație. \n",
    "\n",
    "**Întrebare**:\n",
    "Cât considerați că este entropia într-un *nod frunză*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    Clasa care implementează un arbore de decizie. \n",
    "    Arborele poate fi construit folosind algoritmul ID3 sau Random Tree, în funcție de strategia de împărțire specificată.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 split_strategy: str = 'random',\n",
    "                 max_depth: int = np.inf,\n",
    "                 min_samples_per_node: int = 1):\n",
    "        \"\"\"\n",
    "        Constructor pentru un arbore de decizie\n",
    "        \n",
    "        Args:\n",
    "            split_strategy (string, optional): \n",
    "                Strategia folosită pentru alegerea împărțirii într-un nod. Aceasta poate fi:\n",
    "                - 'id3' - alege împărțirea care maximizează câștigul informațional (folosind algoritmul ID3)\n",
    "                - 'random' - alege aleator o împărțire\n",
    "                Defaults to 'random'.\n",
    "            max_depth (int, optional): \n",
    "                Adâncimea maximă a arborelui. Defaults to infinity.\n",
    "            min_samples_per_node (int, optional): \n",
    "                Numărul minim de exemple dintr-un nod pentru a face o împărțire. \n",
    "                Defaults to 1.\n",
    "        \"\"\"\n",
    "        self._root: DecisionTreeNode | None = None # Rădăcina arborelui\n",
    "        self._split_strategy: str = split_strategy\n",
    "        self._max_depth: int = max_depth\n",
    "        self._min_samples_per_node: int = min_samples_per_node\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def most_frequent_class(y: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Obține clasa majoritară din setul de date\n",
    "        \n",
    "        Args:\n",
    "            y (pd.Series): \n",
    "                Vectorul de clase. Fiecare element reprezintă clasa unui exemplu din setul de date\n",
    "        \n",
    "        Returns:\n",
    "            str: \n",
    "                Clasa majoritară din setul de date\n",
    "        \n",
    "        Examples:\n",
    "            >>> most_frequent_class(pd.Series(['a', 'a', 'b', 'b', 'b']))\n",
    "            'b'\n",
    "        \"\"\"\n",
    "        # TODO 1. Obțineți clasa majoritară din setul de date\n",
    "        # HINT: Folosiți funcția mode() pentru a obține clasa majoritară\n",
    "        return y.mode().iloc[0]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_entropy(y: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Calculează entropia setului de date\n",
    "        \n",
    "        Args:\n",
    "            y (pd.Series): \n",
    "                Vectorul de clase. Fiecare element reprezintă clasa unui exemplu din setul de date\n",
    "        \n",
    "        Returns:\n",
    "            float: \n",
    "                Entropia setului de date\n",
    "        \n",
    "        Examples:\n",
    "            >>> DecisionTree.compute_entropy(pd.Series(['a', 'a', 'b', 'b', 'b']))\n",
    "            0.9709505944546686\n",
    "        \"\"\"\n",
    "        # TODO 2. Calculați entropia setului de date\n",
    "        # HINT: \n",
    "        #   Pentru a obține numărul de apariții ale fiecărei clase puteți folosi funcția value_counts()\n",
    "        # Exemplu: \n",
    "        #   y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "        #   y.value_counts() -> {'b': 3, 'a': 2}\n",
    "        proportions = y.value_counts(normalize = True)\n",
    "        entropy = -np.sum(proportions * np.log2(proportions))\n",
    "        return entropy\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_information_gain(X: pd.DataFrame, y: pd.Series, feature: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculează câștigul informațional al unui atribut din setul de date\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "            feature (str): \n",
    "                Numele atributului pentru care se calculează câștigul informațional\n",
    "        \n",
    "        Returns:\n",
    "            float: \n",
    "                Câștigul informațional al atributului\n",
    "        \n",
    "        Examples:\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> DecisionTree.compute_information_gain(X, y, 'a')\n",
    "            0.4199730940219749\n",
    "        \"\"\"\n",
    "        # TODO 3. Calculați câștigul informațional al atributului `feature`\n",
    "        # HINT: \n",
    "        #   Pentru a selecta doar acele exemple care au valoarea `value` pentru atributul `feature` puteți folosi\n",
    "        #   următoarea expresie: X[X[feature] == value]. Analog, se pot obține clasele corespunzătoare acestor exemple\n",
    "        #   folosind expresia y[X[feature] == value].\n",
    "        \n",
    "        # Se calculează entropia inițială a setului de date\n",
    "        # Se calculează entropia finală a setului de date:\n",
    "        #   Se selectează submulțimea de exemple care au valoarea `value` pentru atributul `feature`\n",
    "        #   Se calculează entropia submulțimii\n",
    "        #   Se calculează ponderea submulțimii\n",
    "        #   Se adaugă entropia submulțimii ponderată la entropia finală\n",
    "        # Câștigul informațional se calculează ca diferența între entropia inițială și entropia finală\n",
    "        total_entropy = DecisionTree.compute_entropy(y)\n",
    "        values = X[feature].unique()\n",
    "        weighted_entropy = 0.0\n",
    "        for value in values:\n",
    "            subset_y = y[X[feature] == value]\n",
    "            weight = len(subset_y) / len(y)\n",
    "            entropy = DecisionTree.compute_entropy(subset_y)\n",
    "            weighted_entropy += weight * entropy\n",
    "        information_gain = total_entropy - weighted_entropy\n",
    "        return information_gain\n",
    "    \n",
    "    \n",
    "    def _select_random_split_feature(self, X: pd.DataFrame, y: pd.Series, attribute_list: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Alege în mod aleator atributul după care se face împărțirea într-un nod\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "            attribute_list (list[str]): \n",
    "                Lista de atribute rămase pentru construcția arborelui\n",
    "        \n",
    "        Returns:\n",
    "            str: \n",
    "                Numele atributului după care se face împărțirea\n",
    "                \n",
    "        Examples:\n",
    "            >>> # Funcția este privată și nu poate fi apelată în afara clasei\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> self._select_random_split_feature(X, y, ['a', 'b'])\n",
    "            'a'\n",
    "        \"\"\"\n",
    "        # TODO 4. Returnați un atribut aleator din lista `attribute_list`\n",
    "        # HINT:\n",
    "        #   Pentru a alege un element aleator dintr-o listă puteți folosi funcția np.random.choice()\n",
    "        return np.random.choice(attribute_list)\n",
    "    \n",
    "    \n",
    "    def _select_best_split_feature(self, X: pd.DataFrame, y: pd.Series, attribute_list: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Alege atributul după care se face împărțirea într-un nod folosind criteriul de câștig informațional\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "            attribute_list (list[str]): \n",
    "                Lista de atribute rămase pentru construcția arborelui\n",
    "        \n",
    "        Returns:\n",
    "            str: \n",
    "                Numele atributului după care se face împărțirea\n",
    "                \n",
    "        Examples:\n",
    "            >>> # Funcția este privată și nu poate fi apelată în afara clasei\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> \n",
    "            >>> # Câștigul informațional:\n",
    "            >>> #    - atributul 'a' -> 0.4199730940219749, \n",
    "            >>> #    - atributul 'b' -> 0.17095059445466854\n",
    "            >>> self._select_best_split_feature(X, y, ['a', 'b'])\n",
    "            'a'\n",
    "        \"\"\"\n",
    "        # TODO 5. Returnați atributul care maximizează câștigul informațional\n",
    "        #  - Se calculează câștigul informațional pentru fiecare atribut din lista `attribute_list`\n",
    "        #  - Se returnează atributul care maximizează câștigul informațional\n",
    "        best_feature = None\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature in attribute_list:\n",
    "            gain = self.compute_information_gain(X, y, feature)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature\n",
    "\n",
    "        return best_feature\n",
    "    \n",
    "    def _generate_tree(self,\n",
    "                       parent_node: DecisionTreeNode | None,\n",
    "                       X: pd.DataFrame,\n",
    "                       y: pd.Series,\n",
    "                       feature_list: list[str],\n",
    "                       select_feature_func: Callable[[pd.DataFrame, pd.Series, list[str]], str]) -> DecisionTreeNode:\n",
    "        \"\"\"\n",
    "        Construiește arborele de decizie pe baza setului de date X și a claselor țintă y\n",
    "        \n",
    "        Args:\n",
    "            parent_node (DecisionTreeNode): \n",
    "                Nodul părinte al nodului curent\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "            feature_list (list[str]): \n",
    "                Lista de atribute rămase pentru construcția arborelui\n",
    "            select_feature_func (Callable[[pd.DataFrame, pd.Series, list[str]], str]):\n",
    "                Funcția folosită pentru a alege atributul după care se face împărțirea\n",
    "                \n",
    "        Returns:\n",
    "            DecisionTreeNode: \n",
    "                Nodul rădăcină al arborelui de decizie construit\n",
    "                \n",
    "        Examples:\n",
    "            >>> # Funcția este privată și nu poate fi apelată în afara clasei\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> self._generate_tree(None, X, y, ['a', 'b'], self._select_random_split_feature)\n",
    "            <DecisionTreeNode>\n",
    "        \"\"\"\n",
    "        # Se face o copie a listei de atribute pentru a nu modifica lista inițială\n",
    "        feature_list = deepcopy(feature_list)\n",
    "        \n",
    "        # Se creează un nou nod pentru arbore\n",
    "        node = DecisionTreeNode()\n",
    "        node.depth = parent_node.depth + 1 if parent_node is not None else 0\n",
    "        node.score = DecisionTree.compute_entropy(y)  \n",
    "        node.num_samples = len(y)\n",
    "        node.label = DecisionTree.most_frequent_class(y)\n",
    "        \n",
    "        # TODO 6. Verificați dacă nodul curent este frunză            \n",
    "        # Nodul curent este frunză dacă:\n",
    "        #   1. Nu mai sunt atribute rămase\n",
    "        #   2. Adâncimea maximă a fost atinsă (se va compara adânimea curentă a nodului cu adâncimea maximă a arborelui)\n",
    "        #   3. Numărul minim de exemple dintr-un nod pentru a face o împărțire nu este îndeplinit (se va compara \n",
    "        #   numărul de exemple din nod cu numărul minim de exemple)\n",
    "        #   4. Toate exemplele din setul de date aparțin unei singure clase (TIP: se poate folosi funcția `nunique()` \n",
    "        #   din pandas pentru a obține numărul de clase distincte)\n",
    "        if(not feature_list or\n",
    "        node.depth >= self._max_depth or\n",
    "        node.num_samples < self._min_samples_per_node or\n",
    "        y.nunique() == 1):\n",
    "            node.is_leaf = True\n",
    "            return node\n",
    "        # TODO 7. Construiți subarborele pentru nodul curent\n",
    "        # 1. Se alege atributul după care se face împărțirea (se va folosi funcția `select_feature_func`)\n",
    "        # 2. Se actualizează lista de atribute rămase pentru construcția subarborilor\n",
    "        # 3. Se actualizează nodul curent cu atributul de împărțire\n",
    "        # 4. Se construiesc subarborii pentru fiecare valoare posibilă a atributului de împărțire:\n",
    "        #   - Se iterează prin valorile posibile ale atributului de împărțire\n",
    "        #   - Se selectează submulțimea de exemple care au valoarea `value` pentru atributul `split_feature`\n",
    "        #   - Se construiește subarborele pentru submulțimea de exemple\n",
    "        #   - Se adaugă subarborele la nodul curent\n",
    "        # HINT:\n",
    "        #   Pentru a obține valorile posibile ale unui atribut puteți folosi funcția unique() din pandas:\n",
    "        #       X[split_feature].unique()\n",
    "        # HINT:\n",
    "        #   Pentru a calcula submulțimea de exemple care au valoarea `value` pentru atributul `split_feature` puteți folosi\n",
    "        #   următoarele expresii: \n",
    "        #       X[X[split_feature] == value].\n",
    "        #       y[X[split_feature] == value].\n",
    "        split_feature = select_feature_func(X, y, feature_list)\n",
    "        feature_list.remove(split_feature)\n",
    "        node.split_feature = split_feature\n",
    "        # Pentru fiecare valoare `value` a atributului `split_feature`\n",
    "        # Se selectează submulțimea de exemple care au valoarea `value` pentru atributul `split_feature`\n",
    "        # Se construiește subarborele pentru submulțimea de exemple\n",
    "        # Se adaugă subarborele la nodul curent\n",
    "        for value in X[split_feature].unique():\n",
    "            X_sub = X[X[split_feature] == value].drop(columns=[split_feature])\n",
    "            y_sub = y[X[split_feature] == value]\n",
    "            child = self._generate_tree(node, X_sub, y_sub, feature_list, select_feature_func)\n",
    "            node.children[value] = child\n",
    "\n",
    "        return node\n",
    "    \n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Construiește arborele de decizie pe baza setului de date. \n",
    "        Va folosi strategia de împărțire specificată în constructor.\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "        \"\"\"\n",
    "        # Selectează funcția de împărțire a nodurilor\n",
    "        if self._split_strategy == 'random':\n",
    "            select_feature_func = self._select_random_split_feature\n",
    "        elif self._split_strategy == 'id3':\n",
    "            select_feature_func = self._select_best_split_feature\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split strategy {self._split_strategy}\")\n",
    "        \n",
    "        self._root = self._generate_tree(parent_node=None,\n",
    "                                         X=X,\n",
    "                                         y=y,\n",
    "                                         feature_list=X.columns.tolist(),\n",
    "                                         select_feature_func=select_feature_func)\n",
    "        \n",
    "    def _predict_once(self, x: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Realizează predicția clasei pentru un singur exemplu x\n",
    "        \n",
    "        Args:\n",
    "            x (pd.Series): \n",
    "                Atributele unui exemplu din setul de date\n",
    "        \n",
    "        Returns:\n",
    "            str: \n",
    "                Clasa prezisă pentru exemplul x\n",
    "                \n",
    "        Examples:\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> model = DecisionTree(split_strategy='random')\n",
    "            >>> model.fit(X, y)\n",
    "            >>> model._predict_once(pd.Series({'a': 1, 'b': 0}))\n",
    "            'a'\n",
    "        \"\"\"\n",
    "        node = self._root\n",
    "        \n",
    "        while node.split_feature is not None:\n",
    "            if node.split_feature in x and x[node.split_feature] in node.children:\n",
    "                node = node.children[x[node.split_feature]]\n",
    "            else:\n",
    "                break\n",
    "        return node.label\n",
    "        \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Realizează predicția claselor pentru un set de date X\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): Setul de date (atributele) pentru care se dorește clasificarea\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Un vector cu clasele prezise pentru fiecare exemplu din X\n",
    "            \n",
    "        Examples:\n",
    "            >>> X = pd.DataFrame({'a': [1, 1, 1, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "            >>> y = pd.Series(['a', 'a', 'b', 'b', 'b'])\n",
    "            >>> model = DecisionTree(split_strategy='random')\n",
    "            >>> model.fit(X, y)\n",
    "            >>> model.predict(X)\n",
    "            array(['a', 'a', 'b', 'b', 'b'], dtype=object)\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_once(x) for _, x in X.iterrows()])\n",
    "    \n",
    "    def get_depth(self) -> int:\n",
    "        \"\"\"\n",
    "        Returnează adâncimea arborelui\n",
    "        \n",
    "        Returns:\n",
    "            int: Adâncimea arborelui\n",
    "        \"\"\"\n",
    "        # Se parcurge arborele pentru a găsi adâncimea maximă\n",
    "        def _get_depth(node: DecisionTreeNode) -> int:\n",
    "            if node is None:\n",
    "                return 0\n",
    "            return max([_get_depth(child) for child in node.children.values()], default=0) + 1\n",
    "        \n",
    "        return _get_depth(self._root)\n",
    "    \n",
    "    def get_number_of_nodes(self) -> int:\n",
    "        \"\"\"\n",
    "        Returnează numărul de noduri din arbore\n",
    "        \n",
    "        Returns:\n",
    "            int: Numărul de noduri din arbore\n",
    "        \"\"\"\n",
    "        # Se parcurge arborele pentru a găsi numărul de noduri\n",
    "        def _get_number_of_nodes(node: DecisionTreeNode) -> int:\n",
    "            if node is None:\n",
    "                return 0\n",
    "            return sum([_get_number_of_nodes(child) for child in node.children.values()], 0) + 1\n",
    "        \n",
    "        return _get_number_of_nodes(self._root)\n",
    "    \n",
    "    def get_tree_graph(self) -> Digraph:\n",
    "        \"\"\"\n",
    "        Construiește reprezentarea grafică a arborelui de decizie folosind biblioteca Graphviz\n",
    "        \n",
    "        Returns:\n",
    "            Digraph: Obiectul Digraph în care se construiește reprezentarea arborelui\n",
    "        \"\"\"\n",
    "        return self._root.get_tree_graph()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Afișează arborele de decizie folosind biblioteca Graphviz. Arborele va fi afișat ca output al celulei.\n",
    "        \"\"\"\n",
    "        return self._root.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testarea funcționalității metodelor implementate\n",
    "\n",
    "În această secțiune veți găsi câteva teste pentru a verifica corectitudinea implementării metodelor din cadrul clasei `DecisionTree`. Aceste teste sunt folosite pentru a verifica dacă metodele implementate returnează rezultatele corecte pentru diferite scenarii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_most_frequent_class\n"
     ]
    }
   ],
   "source": [
    "# Testați funcția `most_frequent_class`\n",
    "assert DecisionTree.most_frequent_class(pd.Series(['a', 'a', 'b', 'b', 'b'])) == 'b', \"Test 1 FAILED: Most frequent class is 'b', but got something else\"\n",
    "assert DecisionTree.most_frequent_class(pd.Series(['a', 'a', 'a', 'b', 'b'])) == 'a', \"Test 2 FAILED: Most frequent class is 'a', but got something else\"\n",
    "print(\"PASSED: test_most_frequent_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_compute_entropy\n"
     ]
    }
   ],
   "source": [
    "# Testați funcția `compute_entropy`\n",
    "assert np.isclose(DecisionTree.compute_entropy(pd.Series(['a', 'a', 'b', 'b', 'b'])), 0.9709505944546686), \"Test 3 FAILED: Entropy is 0.9709505944546686, but got something else\"\n",
    "assert np.isclose(DecisionTree.compute_entropy(pd.Series(['a', 'a', 'a', 'a', 'b'])), 0.7219280948873623), \"Test 4 FAILED: Entropy is 0.7219280948873623, but got something else\"\n",
    "assert np.isclose(DecisionTree.compute_entropy(pd.Series(['a', 'a', 'a', 'a', 'a'])), 0), \"Test 5 FAILED: Entropy is 0, but got something else\"\n",
    "print(\"PASSED: test_compute_entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definim un set de date pentru testare\n",
    "X = pd.DataFrame({'a': [1, 1, 0, 0, 0], 'b': [0, 0, 0, 1, 1]})\n",
    "y = pd.Series(['a', 'a', 'b', 'b', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_compute_information_gain\n"
     ]
    }
   ],
   "source": [
    "# Testați funcția `compute_information_gain`\n",
    "assert np.isclose(DecisionTree.compute_information_gain(X, y, 'a'), 0.9709505944546686), \"Test 6 FAILED: Information gain is 0.9709505944546686, but got something else\"\n",
    "assert np.isclose(DecisionTree.compute_information_gain(X, y, 'b'), 0.4199730940219749), \"Test 7 FAILED: Information gain is 0.4199730940219749, but got something else\"\n",
    "print(\"PASSED: test_compute_information_gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_select_random_split_feature\n"
     ]
    }
   ],
   "source": [
    "# Testați funcția `_select_random_split_feature`\n",
    "model = DecisionTree(split_strategy='random')\n",
    "assert model._select_random_split_feature(X, y, ['a', 'b']) in ['a', 'b'], \"Test 8 FAILED: Selected feature is 'a' or 'b', but got something else\"\n",
    "print(\"PASSED: test_select_random_split_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_select_best_split_feature\n"
     ]
    }
   ],
   "source": [
    "# Testați funcția `_select_best_split_feature`\n",
    "model = DecisionTree(split_strategy='id3')\n",
    "assert model._select_best_split_feature(X, y, ['a', 'b']) == 'a', \"Test 9 FAILED: Selected feature is 'a' or 'b', but got something else\"\n",
    "print(\"PASSED: test_select_best_split_feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afișare arbore de decizie\n",
    "\n",
    "În acest capitol puteți vizualiza arborele de decizie construit folosind algoritmul ID3 sau Random Tree pentru setul de date selectat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setați această variabilă la numărul de rulări dorit pentru a observa diferitele împărțiri ale arborelui\n",
    "NUM_RUNS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"635pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 634.50 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 630.5,-402.75 630.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc440f4a0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc440f4a0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"442.75,-398.75 309.75,-398.75 309.75,-339 442.75,-339 442.75,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.25\" y=\"-381.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Humidity?</text>\n",
       "<text text-anchor=\"middle\" x=\"376.25\" y=\"-364.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.845</text>\n",
       "<text text-anchor=\"middle\" x=\"376.25\" y=\"-346.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 11</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b6570 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b6570</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"367.88,-285.75 256.62,-285.75 256.62,-226 367.88,-226 367.88,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Windy?</text>\n",
       "<text text-anchor=\"middle\" x=\"312.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"312.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 6</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc440f4a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49b6570 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc440f4a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49b6570</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.43,-338.71C351.92,-325.69 342.96,-310.14 334.88,-296.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.96,-294.46 329.93,-287.54 331.89,-297.95 337.96,-294.46\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.83\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">high</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc440daf0 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc440daf0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"496.5,-285.75 386,-285.75 386,-226 496.5,-226 496.5,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"441.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"441.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"441.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc440f4a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc440daf0 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc440f4a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc440daf0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M393.33,-338.71C400.96,-325.69 410.06,-310.14 418.27,-296.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.26,-297.93 423.3,-287.54 415.22,-294.4 421.26,-297.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.77\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d52e0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d52e0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"304.12,-172.75 182.38,-172.75 182.38,-113 304.12,-113 304.12,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"243.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"243.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"243.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 4</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b6570&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d52e0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b6570&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d52e0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.12,-225.71C285.95,-212.56 276.17,-196.84 267.39,-182.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.55,-181.16 262.3,-174.51 264.6,-184.86 270.55,-181.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.63\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4620 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4620</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"503.12,-172.75 381.38,-172.75 381.38,-113 503.12,-113 503.12,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b6570&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4620 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b6570&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4620</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.41,-225.71C362.55,-211.93 382,-195.32 399.14,-180.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.39,-183.37 406.72,-174.21 396.84,-178.04 401.39,-183.37\"/>\n",
       "<text text-anchor=\"middle\" x=\"401.53\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d43b0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d43b0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-59.75 0,-59.75 0,0 110.5,0 110.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d43b0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d43b0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.46,-112.65C183.53,-106.81 173.18,-100.71 163.5,-95 147.53,-85.58 130.25,-75.35 114.28,-65.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.23,-62.98 105.84,-60.89 112.66,-69 116.23,-62.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.88\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d50d0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d50d0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"239.5,-59.75 129,-59.75 129,0 239.5,0 239.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d50d0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d50d0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.75,-112.71C220.83,-99.69 212.56,-84.14 205.11,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.35,-68.75 200.56,-61.57 202.17,-72.04 208.35,-68.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"247.66\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d40e0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d40e0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"368.5,-59.75 258,-59.75 258,0 368.5,0 368.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d40e0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d52e0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d40e0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269.35,-112.7C273.91,-107.02 278.41,-100.96 282.25,-95 287.19,-87.32 291.86,-78.74 296.01,-70.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.13,-71.99 300.3,-61.46 292.82,-68.96 299.13,-71.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.31\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d5a30 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d5a30</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"497.5,-59.75 387,-59.75 387,0 497.5,0 497.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"442.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4620&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5a30 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4620&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5a30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.25,-112.71C442.25,-100.07 442.25,-85.04 442.25,-71.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.75,-71.74 442.25,-61.74 438.75,-71.74 445.75,-71.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"472.62\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d61e0 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d61e0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"626.5,-59.75 516,-59.75 516,0 626.5,0 626.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"571.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"571.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"571.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4620&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d61e0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4620&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d61e0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M484.97,-112.58C492.55,-106.95 500.26,-100.95 507.25,-95 516.97,-86.72 526.96,-77.25 536.07,-68.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.55,-70.64 543.09,-61.06 533.57,-65.71 538.55,-70.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"539.93\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc52a6ff0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"511pt\" height=\"294pt\"\n",
       " viewBox=\"0.00 0.00 510.50 293.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 289.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-289.75 506.5,-289.75 506.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc52a6ff0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc52a6ff0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"318.12,-285.75 196.38,-285.75 196.38,-226 318.12,-226 318.12,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.845</text>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 11</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49a8ad0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49a8ad0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"183.75,-172.75 50.75,-172.75 50.75,-113 183.75,-113 183.75,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"117.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Humidity?</text>\n",
       "<text text-anchor=\"middle\" x=\"117.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"117.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 4</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49a8ad0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49a8ad0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.47,-225.71C202.92,-211.8 181.75,-195.02 163.16,-180.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.47,-177.64 155.46,-174.17 161.12,-183.13 165.47,-177.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.01\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49a9250 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49a9250</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"312.5,-172.75 202,-172.75 202,-113 312.5,-113 312.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"257.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 4</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49a9250 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc49a9250</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.25,-225.71C257.25,-213.07 257.25,-198.04 257.25,-184.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.75,-184.74 257.25,-174.74 253.75,-184.74 260.75,-184.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.62\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc59b10a0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc59b10a0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"441.88,-172.75 330.62,-172.75 330.62,-113 441.88,-113 441.88,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Windy?</text>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.918</text>\n",
       "<text text-anchor=\"middle\" x=\"386.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 3</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc59b10a0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc52a6ff0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc59b10a0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.97,-225.58C307.55,-219.95 315.26,-213.95 322.25,-208 331.97,-199.72 341.96,-190.25 351.07,-181.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.55,-183.64 358.09,-174.06 348.57,-178.71 353.55,-183.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"354.93\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d5670 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d5670</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-59.75 0,-59.75 0,0 110.5,0 110.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49a8ad0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5670 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49a8ad0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5670</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M100.96,-112.71C93.68,-99.69 85,-84.14 77.17,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.32,-68.57 72.38,-61.55 74.21,-71.99 80.32,-68.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.71\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">high</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4800 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4800</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"239.5,-59.75 129,-59.75 129,0 239.5,0 239.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49a8ad0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4800 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49a8ad0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.85,-112.71C142.79,-99.56 152.28,-83.84 160.81,-69.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.58,-71.9 165.75,-61.53 157.59,-68.28 163.58,-71.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.89\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4a10 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4a10</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"373.5,-59.75 263,-59.75 263,0 373.5,0 373.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc59b10a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4a10 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc59b10a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4a10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.38,-112.71C360.33,-99.56 350.7,-83.84 342.04,-69.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.23,-68.22 337.02,-61.52 339.26,-71.88 345.23,-68.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"372.82\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d6840 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d6840</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"502.5,-59.75 392,-59.75 392,0 502.5,0 502.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"447.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"447.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"447.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc59b10a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6840 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc59b10a0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M402.28,-112.71C409.44,-99.69 417.98,-84.14 425.69,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"428.64,-72.01 430.39,-61.56 422.51,-68.63 428.64,-72.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"439.15\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc43d0f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se construiește un arbore de decizie folosind algorithmul Random Tree\n",
    "random_decision_tree = DecisionTree(split_strategy='random', \n",
    "                                    max_depth=MAX_DEPTH, \n",
    "                                    min_samples_per_node=MIN_SAMPLES_PER_NODE)\n",
    "\n",
    "# Rulați această celulă de mai multe ori pentru a observa diferitele împărțiri ale arborelui\n",
    "for _ in range(NUM_RUNS):\n",
    "    random_decision_tree.fit(X_train, y_train)\n",
    "    random_decision_tree.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spre deosebire de Random Tree, algoritmul ID3 alege mereu aceeași împărțire a datelor, deoarece se bazează pe câștigul informațional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"441pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 440.50 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 436.5,-402.75 436.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b5760 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b5760</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"317.75,-398.75 184.75,-398.75 184.75,-339 317.75,-339 317.75,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-381.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Humidity?</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-364.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.845</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-346.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 11</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d62d0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d62d0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"245.12,-285.75 123.38,-285.75 123.38,-226 245.12,-226 245.12,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 6</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b5760&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d62d0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b5760&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d62d0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.65,-338.71C225.71,-325.56 216.22,-309.84 207.69,-295.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.91,-294.28 202.75,-287.53 204.92,-297.9 210.91,-294.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"237.51\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">high</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d50d0 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d50d0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"373.5,-285.75 263,-285.75 263,-226 373.5,-226 373.5,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc49b5760&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d50d0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc49b5760&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d50d0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268.85,-338.71C276.79,-325.56 286.28,-309.84 294.81,-295.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.58,-297.9 299.75,-287.53 291.59,-294.28 297.58,-297.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.89\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d5490 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d5490</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-172.75 0,-172.75 0,-113 110.5,-113 110.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5490 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d5490</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.36,-225.71C134.34,-211.93 115.04,-195.32 98.02,-180.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.38,-178.09 90.51,-174.22 95.81,-183.39 100.38,-178.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.85\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d6420 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d6420</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"239.5,-172.75 129,-172.75 129,-113 239.5,-113 239.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6420 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6420</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.25,-225.71C184.25,-213.07 184.25,-198.04 184.25,-184.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.75,-184.74 184.25,-174.74 180.75,-184.74 187.75,-184.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.62\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d38f0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d38f0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"368.88,-172.75 257.62,-172.75 257.62,-113 368.88,-113 368.88,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Windy?</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d38f0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d62d0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d38f0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.97,-225.58C234.55,-219.95 242.26,-213.95 249.25,-208 258.97,-199.72 268.96,-190.25 278.07,-181.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.55,-183.64 285.09,-174.06 275.57,-178.71 280.55,-183.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.93\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d6de0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d6de0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"303.5,-59.75 193,-59.75 193,0 303.5,0 303.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d38f0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6de0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d38f0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d6de0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.17,-112.71C288.54,-99.69 279.44,-84.14 271.23,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.28,-68.4 266.2,-61.54 268.24,-71.93 274.28,-68.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.14\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4860 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4860</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"432.5,-59.75 322,-59.75 322,0 432.5,0 432.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d38f0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4860 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d38f0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4860</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.07,-112.71C337.58,-99.69 346.54,-84.14 354.62,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.61,-71.95 359.57,-61.54 351.54,-68.46 357.61,-71.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.83\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc49b4620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"441pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 440.50 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 436.5,-402.75 436.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc5ffd400 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc5ffd400</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"317.75,-398.75 184.75,-398.75 184.75,-339 317.75,-339 317.75,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-381.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Humidity?</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-364.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.845</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-346.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 11</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4110 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4110</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"245.12,-285.75 123.38,-285.75 123.38,-226 245.12,-226 245.12,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 6</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc5ffd400&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4110 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc5ffd400&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d4110</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.65,-338.71C225.71,-325.56 216.22,-309.84 207.69,-295.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.91,-294.28 202.75,-287.53 204.92,-297.9 210.91,-294.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"237.51\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">high</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d1490 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d1490</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"373.5,-285.75 263,-285.75 263,-226 373.5,-226 373.5,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc5ffd400&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d1490 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc5ffd400&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d1490</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268.85,-338.71C276.79,-325.56 286.28,-309.84 294.81,-295.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.58,-297.9 299.75,-287.53 291.59,-294.28 297.58,-297.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.89\" y=\"-307.7\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d42f0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d42f0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-172.75 0,-172.75 0,-113 110.5,-113 110.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d42f0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d42f0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.36,-225.71C134.34,-211.93 115.04,-195.32 98.02,-180.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.38,-178.09 90.51,-174.22 95.81,-183.39 100.38,-178.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.85\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d7050 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d7050</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"239.5,-172.75 129,-172.75 129,-113 239.5,-113 239.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d7050 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d7050</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.25,-225.71C184.25,-213.07 184.25,-198.04 184.25,-184.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.75,-184.74 184.25,-174.74 180.75,-184.74 187.75,-184.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.62\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43bf8c0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43bf8c0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"368.88,-172.75 257.62,-172.75 257.62,-113 368.88,-113 368.88,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Windy?</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 1.000</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43bf8c0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d4110&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43bf8c0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.97,-225.58C234.55,-219.95 242.26,-213.95 249.25,-208 258.97,-199.72 268.96,-190.25 278.07,-181.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.55,-183.64 285.09,-174.06 275.57,-178.71 280.55,-183.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.93\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d77d0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d77d0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"303.5,-59.75 193,-59.75 193,0 303.5,0 303.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"248.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43bf8c0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d77d0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43bf8c0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d77d0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.17,-112.71C288.54,-99.69 279.44,-84.14 271.23,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.28,-68.4 266.2,-61.54 268.24,-71.93 274.28,-68.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.14\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43d79e0 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43d79e0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"432.5,-59.75 322,-59.75 322,0 432.5,0 432.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"377.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc43bf8c0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d79e0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc43bf8c0&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc43d79e0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.07,-112.71C337.58,-99.69 346.54,-84.14 354.62,-70.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.61,-71.95 359.57,-61.54 351.54,-68.46 357.61,-71.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.83\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc446f740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se construiește un arbore de decizie folosind algorithmul ID3\n",
    "id3_decision_tree = DecisionTree(split_strategy='id3', \n",
    "                                 max_depth=MAX_DEPTH, \n",
    "                                 min_samples_per_node=MIN_SAMPLES_PER_NODE)\n",
    "for _ in range(NUM_RUNS):\n",
    "    id3_decision_tree.fit(X_train, y_train)\n",
    "    id3_decision_tree.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru setul de date *Tennis*, arborele de decizie construit folosind algoritmul ID3 pentru hiperparametrii *max_depth=3* și *min_samples_per_node=1* este:\n",
    "\n",
    "![](res-id3/id3_tennis_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Păduri de arbori aleatori)\n",
    "\n",
    "Pădurile de arbori aleatori sunt o metodă de învățare supervizată în care se folosesc mai mulți arbori de decizie în \n",
    "procesul de clasificare. Clasificarea se face prin votul majorității arborilor. Această tehnică crește robustețea \n",
    "clasificatorului și reduce overfitting-ul.\n",
    "\n",
    "Pentru a construi o pădure de arbori aleatori se urmează următorii pași:\n",
    "1. Pentru fiecare arbore din pădure care se dorește a fi construit:\n",
    "   1. Se alege un subset aleator din setul de date de antrenare\n",
    "   2. Se aleg aleator $m$ atribute din setul de atribute inițial\n",
    "   3. Se construiește un arbore de decizie pe subsetul de date ales\n",
    "   4. Se adaugă arborele la pădure\n",
    "\n",
    "Prin construirea arborilor pe subseturi aleatoare din setul de date, se obțin arbori diferiți.\n",
    "\n",
    "### Discuții\n",
    "* Porniți de la *n = 100*, *d = 3* și submulțimi formate din 50% din elementele lui X alese la întamplare și experimentați cu acești hiperparametrii.\n",
    "* Comparați rezultatele obținute folosind un singur arbore construit cu ID3 și o pădure de arbori aleatori. Discuție după *zgomot*, *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    Clasa care implementează un clasificator de tip pădure de arbori aleatori.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_estimators: int = 100,\n",
    "                 max_depth: int = 3,\n",
    "                 min_samples_per_node: int = 1,\n",
    "                 split_strategy: str = 'random',\n",
    "                 subset_size_ratio: float = 0.5,\n",
    "                 subset_feature_ratio: float = 0.75):\n",
    "        \"\"\"\n",
    "        Constructor pentru un clasificator de tip pădure de arbori aleatori\n",
    "        \n",
    "        Args:\n",
    "            n_estimators (int, optional): \n",
    "                Numărul de arbori din pădure. Defaults to 100.\n",
    "            max_depth (int, optional): \n",
    "                Adâncimea maximă a fiecărui arbore. Defaults to 3.\n",
    "            min_samples_per_node (int, optional): \n",
    "                Numărul minim de exemple dintr-un nod pentru a face o împărțire. \n",
    "                Defaults to 1.\n",
    "            split_strategy (str, optional):\n",
    "                Strategia folosită pentru alegerea împărțirii într-un nod. Aceasta poate fi:\n",
    "                - 'id3' - alege împărțirea care maximizează câștigul informațional (folosind algoritmul ID3)\n",
    "                - 'random' - alege aleator o împărțire\n",
    "                Defaults to 'random'.\n",
    "            subset_size_ratio (float, optional):\n",
    "                Raportul de dimensiune al subsetului de date folosit pentru construirea fiecărui arbore comparativ cu\n",
    "                dimensiunea setului de date inițial. Trebuie să fie un număr între 0 și 1.\n",
    "                Defaults to 0.5.\n",
    "            subset_feature_ratio (float, optional):\n",
    "                Raportul de dimensiune al subsetului de atribute folosit pentru construirea fiecărui arbore comparativ cu\n",
    "                dimensiunea setului de atribute inițial. Trebuie să fie un număr între 0 și 1.\n",
    "                Defaults to 0.75.\n",
    "        \"\"\"\n",
    "        assert 0 < subset_size_ratio <= 1, \"subset_size_ratio must be between 0 and 1\"\n",
    "        assert 0 < subset_feature_ratio <= 1, \"subset_feature_ratio must be between 0 and 1\"\n",
    "        \n",
    "        self._trees: list[DecisionTree] = []\n",
    "        self._n_estimators: int = n_estimators\n",
    "        self._max_depth: int = max_depth\n",
    "        self._min_samples_per_node: int = min_samples_per_node\n",
    "        self._split_strategy: str = split_strategy\n",
    "        self._subset_size_ratio: float = subset_size_ratio\n",
    "        self._subset_feature_ratio: float = subset_feature_ratio\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Construiește pădurea de arbori aleatori pe baza setului de date\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): \n",
    "                Setul de date (atributele)\n",
    "            y (pd.Series): \n",
    "                Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "        \"\"\"\n",
    "        # TODO 8. Construiți pădurea de arbori aleatori\n",
    "        # Pentru a construi pădurea de arbori aleatori se vor parcurge următorii pași pentru fiecare estimator:\n",
    "        #   1. Se alege un subset aleator din setul de date de antrenare. \n",
    "        #      Subsetul va conține un număr de exemple egal cu \n",
    "        #      `subset_size_ratio` * numărul de exemple din setul de date\n",
    "        #   2. Se construiește un arbore de decizie pe subsetul de date\n",
    "        #   3. Se adaugă arborele la pădure\n",
    "        # HINT:\n",
    "        #   Pentru a alege un subset aleator din setul de date puteți folosi funcția np.random.choice() pentru a selecta\n",
    "        #   indicii exemplelor care vor fi folosiți în construcția arborelui. Indicii vor fi extrași fără înlocuire. \n",
    "        #   Exemplu:\n",
    "        #       indices = np.random.choice(X.shape[0], size=int(self._subset_size_ratio * X.shape[0]), replace=False)\n",
    "        #       X_subset = X.iloc[indices]  # Selectează doar exemplele cu indicii aleși (atributele rămân aceleași)\n",
    "        #       y_subset = y.iloc[indices]\n",
    "        #   Funcția `np.random.choice()` va selecta indicii aleator din intervalul [0, X.shape[0]) și va returna un subset\n",
    "        #   de dimensiune `int(self._subset_size_ratio * X.shape[0])` cu indicii selectați.\n",
    "        #   Indicii vor fi un np.ndarray de forma [0, 1, 2, 3, 5, 9, ...].\n",
    "        #\n",
    "        # HINT: \n",
    "        #   Pentru a extrage un subset de atribute puteți folosi următoarea expresie:\n",
    "        #       X_subset = X[features]\n",
    "        #   unde `features` este o listă cu numele atributelor pe care doriți să le folosiți\n",
    "        self._trees = []\n",
    "        for _ in range(self._n_estimators):\n",
    "            # Se selectează un subset aleator din setul de date\n",
    "            # Se selectează din X un subset de atribute\n",
    "            # Se construiește un arbore de decizie pe subsetul de date\n",
    "            # Se adaugă arborele la pădure\n",
    "            indices = np.random.choice(\n",
    "            X.shape[0],\n",
    "            size=int(self._subset_size_ratio * X.shape[0]),\n",
    "            replace=False\n",
    "        )\n",
    "            X_subset = X.iloc[indices]\n",
    "            y_subset = y.iloc[indices]\n",
    "        \n",
    "            tree = DecisionTree(\n",
    "            max_depth=self._max_depth,\n",
    "            min_samples_per_node=self._min_samples_per_node,\n",
    "            split_strategy='random'  # folosim împărțiri aleatoare pentru Random Forest\n",
    "        )\n",
    "            tree.fit(X_subset, y_subset)\n",
    "            self._trees.append(tree)   \n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Realizează predicția claselor pentru un set de date X\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): Setul de date (atributele) pentru care se dorește clasificarea\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Un vector cu clasele prezise pentru fiecare exemplu din X\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for tree in self._trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "            \n",
    "        # Se alege clasa majoritară pentru fiecare exemplu din setul de date\n",
    "        return np.array([Counter(pred).most_common(1)[0][0] for pred in np.array(predictions).T])\n",
    "    \n",
    "    def display(self, max_trees: int = 5):\n",
    "        \"\"\"\n",
    "        Afișează arborii din pădure\n",
    "        \n",
    "        Args:\n",
    "            max_trees (int, optional): \n",
    "                Numărul maxim de arbori care vor fi afișați. Defaults to 5.\n",
    "        \n",
    "        Warnings:\n",
    "            Afișarea arborilor nu este indicată pentru un număr mare de estimatori\n",
    "        \"\"\"\n",
    "        for i, tree in enumerate(self._trees[:max_trees]):\n",
    "            print()\n",
    "            tree.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplu de utilizare a clasei RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"119pt\" height=\"68pt\"\n",
       " viewBox=\"0.00 0.00 118.50 67.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 63.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-63.75 114.5,-63.75 114.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fe6f0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fe6f0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-59.75 0,-59.75 0,0 110.5,0 110.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc598c620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"119pt\" height=\"68pt\"\n",
       " viewBox=\"0.00 0.00 118.50 67.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 63.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-63.75 114.5,-63.75 114.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fe960 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fe960</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-59.75 0,-59.75 0,0 110.5,0 110.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc4375ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"382pt\" height=\"294pt\"\n",
       " viewBox=\"0.00 0.00 381.50 293.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 289.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-289.75 377.5,-289.75 377.5,4 -4,4\"/>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fff50 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fff50</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"306.88,-285.75 195.62,-285.75 195.62,-226 306.88,-226 306.88,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-268.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Windy?</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-251.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"251.25\" y=\"-233.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 5</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47feb10 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47feb10</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"245.12,-172.75 123.38,-172.75 123.38,-113 245.12,-113 245.12,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Split: Outlook?</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: 0.811</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 4</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fff50&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47feb10 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fff50&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47feb10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.65,-225.71C225.71,-212.56 216.22,-196.84 207.69,-182.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.91,-181.28 202.75,-174.53 204.92,-184.9 210.91,-181.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.51\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fd5e0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fd5e0</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"373.5,-172.75 263,-172.75 263,-113 373.5,-113 373.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-155.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-138.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"318.25\" y=\"-120.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fff50&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fd5e0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fff50&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fd5e0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268.85,-225.71C276.79,-212.56 286.28,-196.84 294.81,-182.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.58,-184.9 299.75,-174.53 291.59,-181.28 297.58,-184.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"305.26\" y=\"-194.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fe570 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fe570</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"110.5,-59.75 0,-59.75 0,0 110.5,0 110.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: no</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"55.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fe570 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fe570</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.36,-112.71C134.34,-98.93 115.04,-82.32 98.02,-67.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.38,-65.09 90.51,-61.22 95.81,-70.39 100.38,-65.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.85\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">sunny</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47fd850 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47fd850</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"239.5,-59.75 129,-59.75 129,0 239.5,0 239.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"184.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 1</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fd850 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47fd850</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.25,-112.71C184.25,-100.07 184.25,-85.04 184.25,-71.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.75,-71.74 184.25,-61.74 180.75,-71.74 187.75,-71.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.62\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">overcast</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47ffc80 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47ffc80</title>\n",
       "<polygon fill=\"#bcee68\" stroke=\"black\" points=\"368.5,-59.75 258,-59.75 258,0 368.5,0 368.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-42.45\" font-family=\"Times,serif\" font-size=\"14.00\">Label: yes</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-25.2\" font-family=\"Times,serif\" font-size=\"14.00\">Score: &#45;0.000</text>\n",
       "<text text-anchor=\"middle\" x=\"313.25\" y=\"-7.95\" font-family=\"Times,serif\" font-size=\"14.00\">Samples: 2</text>\n",
       "</g>\n",
       "<!-- __main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47ffc80 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>__main__.DecisionTreeNode object at 0x7f3cc47feb10&#45;&gt;__main__.DecisionTreeNode object at 0x7f3cc47ffc80</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.97,-112.58C234.55,-106.95 242.26,-100.95 249.25,-95 258.97,-86.72 268.96,-77.25 278.07,-68.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.55,-70.64 285.09,-61.06 275.57,-65.71 280.55,-70.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.93\" y=\"-81.7\" font-family=\"Times,serif\" font-size=\"14.00\">rain</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f3cc598c620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se construiește un clasificator de tip pădure de arbori aleatori\n",
    "random_forest = RandomForest(n_estimators=3, \n",
    "                             max_depth=3, \n",
    "                             min_samples_per_node=MIN_SAMPLES_PER_NODE, \n",
    "                             split_strategy='id3')\n",
    "\n",
    "# Se antrenează clasificatorul\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Afișăm arborii creați\n",
    "random_forest.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datele de intrare:\n",
      "Outlook          rain\n",
      "Temperature      cool\n",
      "Humidity       normal\n",
      "Windy            True\n",
      "Name: 5, dtype: object\n",
      "\n",
      "Clasa reală:\n",
      "no\n",
      "\n",
      "Clasa prezisă:\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# Se realizează predicția claselor pentru setul de date de test\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "print(\"Datele de intrare:\")\n",
    "print(X_test.iloc[0])\n",
    "\n",
    "print(\"\\nClasa reală:\")\n",
    "print(y_test.iloc[0])\n",
    "\n",
    "print(\"\\nClasa prezisă:\")\n",
    "print(y_pred_rf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjYqUPSbe1gG"
   },
   "source": [
    "## Evaluarea modelelor\n",
    "\n",
    "Un exemplu clasificat poate aparține unei clase pozitive sau negative și poate fi clasificat corect sau greșit de un model de clasificare. În funcție de aceste două caracteristici, un exemplu poate fi clasificat în una din cele patru categorii:\n",
    "* **True Positive (TP)**: exemplu pozitiv clasificat corect\n",
    "* **True Negative (TN)**: exemplu negativ clasificat corect\n",
    "* **False Positive (FP)**: exemplu negativ clasificat greșit\n",
    "* **False Negative (FN)**: exemplu pozitiv clasificat greșit\n",
    "\n",
    "$$ \n",
    "    TP = True\\ Positives\\\\\n",
    "    FP = False\\ Positives\\\\\n",
    "    TN = True\\ Negatives\\\\\n",
    "    FN = False\\ Negatives\\\\\n",
    "$$\n",
    "\n",
    "Pentru a evalua modelele de clasificare vom folosi următoarele metrici:\n",
    "* **Acuratețe (Accuracy)**: reprezintă raportul între numărul de exemple clasificate corect și numărul total de exemple din setul de date.\n",
    "* **Precizie (Precision)**: reprezintă raportul între numărul de exemple clasificate corect cu clasa `c` și numărul total de exemple clasificate cu clasa `c`.\n",
    "* **Acoperire (Recall)**: reprezintă raportul între numărul de exemple clasificate corect cu clasa `c` și numărul total de exemple din setul de date cu clasa `c`.\n",
    "* **Scorul F1 (F1 Score)**: reprezintă media armonică între precizie și acoperire.\n",
    "\n",
    "$$\n",
    "    accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    f1\\_score = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}\n",
    "$$\n",
    "\n",
    "De asemenea, pentru a evalua corectitudinea modelelor de clasificare vom folosi următoarele concepte:\n",
    "* **Matrice de confuzie (Confusion Matrix)**: este o matrice care arată numărul de exemple clasificate corect și numărul de exemple clasificate greșit pentru fiecare clasă.\n",
    "\n",
    "\n",
    "$$\n",
    "    \\begin{array}{|c|c|c|}\n",
    "    \\hline\n",
    "    & \\text{Predicție pozitivă} & \\text{Predicție negativă} \\\\\n",
    "    \\hline\n",
    "    \\text{Clasa pozitivă} & TP & FN \\\\\n",
    "    \\hline\n",
    "    \\text{Clasa negativă} & FP & TN \\\\\n",
    "    \\hline\n",
    "    \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred: pd.Series, y_true: pd.Series, c: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculează precizia (precision) unui clasificator. \n",
    "    Precizia este definită ca raportul între numărul de exemple clasificate corect cu clasa `c` și numărul total de exemple clasificate cu clasa `c`.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (pd.Series): \n",
    "            Clasele prezise de clasificator\n",
    "        y_true (pd.Series): \n",
    "            Clasele reale din setul de date\n",
    "        c (str):\n",
    "            Clasa pentru care se calculează precizia\n",
    "\n",
    "    Returns:\n",
    "        float: \n",
    "            Precizia clasificatorului\n",
    "            \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> precision(y_pred=pd.Series(['a', 'a', 'a', 'a', 'b']), \n",
    "    >>>           y_true=pd.Series(['a', 'a', 'a', 'b', 'b']), \n",
    "    >>>           c='a')\n",
    "    0.75\n",
    "    \"\"\"\n",
    "    # Doar exemplele clasificate cu clasa c sunt relevante pentru calculul preciziei\n",
    "    pred_c = y_pred[y_pred == c]\n",
    "    \n",
    "    # Extrage doar exemplele clasificate corect cu clasa c\n",
    "    true_c = y_true[(y_pred == c) & (y_true == c)]\n",
    "    \n",
    "    # Calculul preciziei\n",
    "    if len(pred_c) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(true_c) / len(pred_c)\n",
    "    \n",
    "def recall(y_pred: pd.Series, y_true: pd.Series, c: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculează acoperirea (recall) unui clasificator. \n",
    "    Acoperirea este definită ca raportul între numărul de exemple clasificate corect cu clasa `c` și numărul total de exemple din setul de date cu clasa `c`.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (pd.Series): \n",
    "            Clasele prezise de clasificator\n",
    "        y_true (pd.Series): \n",
    "            Clasele reale din setul de date\n",
    "        c (str): \n",
    "            Clasa pentru care se calculează acoperirea\n",
    "\n",
    "    Returns:\n",
    "        float: \n",
    "            Acoperirea clasificatorului\n",
    "            \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> recall(y_pred=pd.Series(['a', 'a', 'a', 'a', 'b']),\n",
    "    >>>        y_true=pd.Series(['a', 'a', 'a', 'b', 'b']),\n",
    "    >>>        c='a')\n",
    "    1.0     \n",
    "    \"\"\"\n",
    "    # Doar exemplele din setul de date cu clasa c sunt relevante pentru calculul acoperirii\n",
    "    true_c = y_true[y_true == c]\n",
    "    \n",
    "    # Extrage doar exemplele clasificate corect cu clasa c\n",
    "    pred_c = y_pred[(y_pred == c) & (y_true == c)]\n",
    "    \n",
    "    # Calculul acoperirii\n",
    "    if len(true_c) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(pred_c) / len(true_c)\n",
    "    \n",
    "def f1_score(y_pred: pd.Series, y_true: pd.Series, c: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculează scorul F1 al unui clasificator. \n",
    "    Scorul F1 este definit ca media armonică între precizie și acoperire.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (pd.Series): \n",
    "            Clasele prezise de clasificator\n",
    "        y_true (pd.Series): \n",
    "            Clasele reale din setul de date\n",
    "        c (str):\n",
    "            Clasa pentru care se calculează scorul F1\n",
    "\n",
    "    Returns:\n",
    "        float: \n",
    "            Scorul F1 al clasificatorului\n",
    "            \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> f1_score(y_pred=pd.Series(['a', 'a', 'a', 'a', 'b']),\n",
    "    >>>           y_true=pd.Series(['a', 'a', 'a', 'b', 'b']),\n",
    "    >>>           c='a')\n",
    "    0.8571428571428571\n",
    "    \"\"\"\n",
    "    # Calculul scorului F1\n",
    "    p = precision(y_pred, y_true, c)\n",
    "    r = recall(y_pred, y_true, c)\n",
    "    \n",
    "    if p + r == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * p * r / (p + r)\n",
    "    \n",
    "def accuracy(y_pred: pd.Series, y_true: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculează acuratețea unui clasificator. \n",
    "    Acuratețea este definită ca raportul între numărul de exemple clasificate corect și numărul total de exemple din setul de date.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (pd.Series): \n",
    "            Clasele prezise de clasificator\n",
    "        y_true (pd.Series): \n",
    "            Clasele reale din setul de date\n",
    "\n",
    "    Returns:\n",
    "        float: \n",
    "            Acuratețea clasificatorului\n",
    "            \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> accuracy(pd.Series(['a', 'a', 'a', 'a', 'b']), pd.Series(['a', 'a', 'a', 'b', 'b']))\n",
    "    0.8\n",
    "    \"\"\"\n",
    "    # Calculul acurateței\n",
    "    return (y_pred == y_true).sum() / len(y_true)\n",
    "\n",
    "def evaluate(tree: DecisionTree, X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    Evaluează un arbore de decizie / pădure de arbori de decizie pe un set de date X.\n",
    "    Pentru evaluare se va folosi de funcția `predict` a arborelui de decizie / pădurii de arbori de decizie.\n",
    "    \n",
    "    Rezultatul va fi un tabel cu metricile de evaluare: acuratețe, precizie, recall, f1-score.\n",
    "        \n",
    "    Args:\n",
    "        tree (DecisionTreeNode): \n",
    "            Arborele de decizie / pădurea de arbori de decizie\n",
    "        X (pd.DataFrame): \n",
    "            Setul de date (atributele) pentru care se dorește clasificarea\n",
    "        y (pd.Series):\n",
    "            Clasele corespunzătoare fiecărui exemplu din setul de date\n",
    "    Examples\n",
    "    --------\n",
    "    >>> evaluate(tree, X_test)\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "             acc       0.61      0.73      0.66        90\n",
    "            good       0.00      0.00      0.00        11\n",
    "           unacc       0.91      0.92      0.92       231\n",
    "           vgood       0.00      0.00      0.00        14\n",
    "    \n",
    "        accuracy                           0.81       346\n",
    "       macro avg       0.38      0.41      0.39       346\n",
    "    weighted avg       0.77      0.81      0.78       346\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    y_pred = tree.predict(X)\n",
    "    print(classification_report(y, y_pred, zero_division=0))\n",
    "    \n",
    "def plot_confusion_matrix(y_pred: pd.Series, y_true: pd.Series):\n",
    "    \"\"\"\n",
    "    Construiește matricea de confuzie pentru un clasificator.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (pd.Series): \n",
    "            Clasele prezise de clasificator\n",
    "        y_true (pd.Series): \n",
    "            Clasele reale din setul de date\n",
    "    \"\"\"\n",
    "    confusion_matrix = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'], dropna=False)\n",
    "\n",
    "    # Adăugăm toate clasele prezise și reale pentru a avea toate clasele în matricea de confuzie\n",
    "    all_classes = np.unique(list(y_true) + list(y_pred))\n",
    "    confusion_matrix = confusion_matrix.reindex(index=all_classes, columns=all_classes, fill_value=0)\n",
    "\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectam setul de date Chess pentru evaluare, deoarece acesta are mai multe exemple\n",
    "data_cars = load_dataset('chess')\n",
    "X_train, y_train, X_test, y_test = split_train_test(data_cars, \"class\", test_size=0.2)\n",
    "\n",
    "print(\"Train set size: \", len(X_train))\n",
    "print(\"Test set size: \", len(X_test))\n",
    "print(\"Number of classes: \", y_train.nunique())\n",
    "print(\"Number of features: \", len(X_train.columns))\n",
    "\n",
    "print(\"\\nNumber of examples per class in train set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizăm influența parametrului `max_depth` asupra performanței clasificatorului Decision Tree\n",
    "max_depth_values = list(range(1, 20))\n",
    "\n",
    "accuracies = []\n",
    "num_nodes = []\n",
    "\n",
    "for max_depth in tqdm(max_depth_values):\n",
    "    decision_tree = DecisionTree(split_strategy='id3', \n",
    "                                 max_depth=max_depth, \n",
    "                                 min_samples_per_node=2)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    accuracies += [accuracy(decision_tree.predict(X_test), y_test)]\n",
    "    num_nodes += [decision_tree.get_number_of_nodes()]\n",
    "    \n",
    "# Afișăm graficul cu acuratețea clasificatorului în funcție de adâncimea maximă a arborelui\n",
    "plt.plot(max_depth_values, accuracies)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Afișăm graficul cu numărul de noduri din arbore în funcție de adâncimea maximă a arborelui\n",
    "plt.plot(max_depth_values, num_nodes)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.title('Decision Tree Number of Nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creșterea adâncimii arborelui de decizie duce la creșterea acurateței clasificatorului pe setul de date de test, până\n",
    " la un anumit punct, după care acuratețea se stabilizează. Acest lucru se datorează faptului că arborele a ajuns\n",
    " la o adâncime la care a învățat toate exemplele din setul de date de antrenare.\n",
    "    \n",
    "În mod normal, creșterea adâncimii arborelui de decizie duce la creșterea complexității modelului, ceea ce poate duce la\n",
    " overfitting. Overfitting-ul apare atunci când modelul învață prea bine setul de date de antrenare și nu generalizează\n",
    " corect pe setul de date de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizăm influența parametrului `n_estimators` asupra performanței clasificatorului Random Forest\n",
    "n_estimators_values = list(range(1, 31, 2))\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for n_estimators in tqdm(n_estimators_values):\n",
    "    random_forest = RandomForest(n_estimators=n_estimators, \n",
    "                                 max_depth=3, \n",
    "                                 min_samples_per_node=2, \n",
    "                                 split_strategy='id3')\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    accuracies += [accuracy(random_forest.predict(X_test), y_test)]\n",
    "    \n",
    "plt.plot(n_estimators_values, accuracies)\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se poate observa, creșterea numărului de estimatori din pădurea de arbori aleatori duce la creșterea \n",
    "acurateței clasificatorului până la un anumit punct, după care acuratețea se stabilizează, iar creșterea numărului de\n",
    " estimatori nu mai aduce beneficii semnificative. Din acest motiv, este important să alegem un număr optim de \n",
    " estimatori pentru a obține un echilibru între performanță și timp de antrenare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparăm rezultatele obținute folosind un singur arbore construit cu ID3 și o pădure de arbori aleatori\n",
    "id3_decision_tree = DecisionTree(split_strategy='id3', \n",
    "                                 max_depth=100, \n",
    "                                 min_samples_per_node=2)\n",
    "random_forest = RandomForest(n_estimators=50, \n",
    "                             max_depth=3, \n",
    "                             min_samples_per_node=2, \n",
    "                             split_strategy='id3')\n",
    "\n",
    "id3_decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"ID3 Decision Tree:\")\n",
    "evaluate(id3_decision_tree, X_test, y_test)\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "evaluate(random_forest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(id3_decision_tree.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(random_forest.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparare cu implementarea din biblioteca `sklearn`\n",
    "\n",
    "`sklearn` oferă o implementări pentru arborele de decizie și pădurea de arbori aleatori. În această secțiune vom compara rezultatele obținute folosind implementările noastre cu cele din bibliotecă.\n",
    "\n",
    "Spre deosebire de implementarea noastră, arborii din `sklearn` nu suportă variabile categorice. Din acest motiv, vom converti variabilele categorice în variabile numerice, folosind funcția `pd.get_dummies()` care realizează codificarea one-hot (*one-hot encoding*).\n",
    "\n",
    "#### One-Hot Encoding\n",
    "\n",
    "One-Hot Encoding este o tehnică de preprocesare a datelor care transformă variabilele categorice în variabile numerice. Această tehnică constă în crearea unui nou atribut pentru fiecare valoare a variabilei categorice, atribut care va avea valoarea 1 dacă exemplul aparține acelei categorii și 0 în caz contrar.\n",
    "\n",
    "**Exemplu:**\n",
    "\n",
    "Avem atributul categoric `Color` cu valorile `Red`, `Green`, `Blue`. După aplicarea One-Hot Encoding, atributul `Color` va fi înlocuit de 3 atribute: `Color_Red`, `Color_Green`, `Color_Blue`.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr> \n",
    "    <td> Setul de date inițial </td> \n",
    "    <td> Setul de date Once-Hot Encoded </td> \n",
    "</tr>\n",
    "\n",
    "<tr> <td>\n",
    "\n",
    "| Color |\n",
    "|-------|\n",
    "| Red   |\n",
    "| Green |\n",
    "| Blue  |\n",
    "| Red   |\n",
    "\n",
    "</td> <td>\n",
    "\n",
    "| Color_Red | Color_Green | Color_Blue |\n",
    "|-----------|-------------|------------|\n",
    "| 1         | 0           | 0          |\n",
    "| 0         | 1           | 0          |\n",
    "| 0         | 0           | 1          |\n",
    "| 1         | 0           | 0          |\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertim variabilele categorice în variabile numerice folosind One-Hot Encoding\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "\n",
    "# Setul de antrenare poate conține alte valori ale atributelor față de setul \n",
    "# de date de test, ceea ce poate duce la un număr diferit de atribute \n",
    "# în cele două seturi după aplicarea One-Hot Encoding.\n",
    "# Vom completa seturile de date cu coloane lipsă\n",
    "X_train_encoded = X_train_encoded.reindex(columns=X_test_encoded.columns, fill_value=0)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "print(\"Number of features in train set after encoding: \", len(X_train_encoded.columns))\n",
    "print(\"Number of features in test set after encoding: \", len(X_test_encoded.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Antrenăm un arbore de decizie folosind implementarea din `sklearn`\n",
    "sklearn_decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=100)\n",
    "sklearn_decision_tree.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluăm arborele de decizie\n",
    "print(\"Decision Tree (sklearn):\")\n",
    "evaluate(sklearn_decision_tree, X_test_encoded, y_test)\n",
    "\n",
    "# Afișăm matricea de confuzie\n",
    "plot_confusion_matrix(sklearn_decision_tree.predict(X_test_encoded), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Antrenăm o pădure de arbori aleatori folosind implementarea din `sklearn`\n",
    "sklearn_random_forest = RandomForestClassifier(n_estimators=50, max_depth=3)\n",
    "sklearn_random_forest.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluăm pădurea de arbori aleatori\n",
    "print(\"Random Forest (sklearn):\")\n",
    "evaluate(sklearn_random_forest, X_test_encoded, y_test)\n",
    "\n",
    "# Afișăm matricea de confuzie\n",
    "plot_confusion_matrix(sklearn_random_forest.predict(X_test_encoded), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnH2b3D0kXTd"
   },
   "source": [
    "## Extra informații"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5JsikeLkZJc"
   },
   "source": [
    "### ID3 exemplu\n",
    "Un exemplu mai detaliat pentru construcția arborelui de decizie ID3 se poate găsi [aici](https://github.com/cs-pub-ro/ML/blob/master/lab/lab2/id3_example.pdf).\n",
    "\n",
    "### CART\n",
    "Un alt algoritm utilizat poartă denumirea de CART (eng. Classification and Regression Tree). Dacă **ID3** utilizeaza **câștigul informațional (eng. information gain)**, **CART** utilizeaza o altă metrică numită **index-ul Gini (eng. Gini index sau Gini impurity)**.\n",
    "\n",
    "Pentru implementare, se urmăresc exact aceeași [pași ca la ID3](#scrollTo=rjYqUPSbe1gG), singura diferentă fiind modul în care se calculează atributul utilizat într-un *nod intermediar*.\n",
    "$$\n",
    "Gini(X, a) = 1 - \\sum_{c \\in C}{p(c | attr(X) = a) ^2}\n",
    "\\\\\n",
    "a^* = \\underset{a \\in A}{\\operatorname{arg min}}\\ Gini(X, a)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0CLd24Gc0Qoz",
    "cxigVMh10QsL",
    "-YWxF81W1jlU",
    "TxWxuiO_16tZ",
    "kQvktw_WbZpk",
    "oQvzJhiWfzm9",
    "QVVLxc0geBix",
    "pyJFPSkseHlf",
    "GVpmhw63j89K",
    "kgYby0WVetLL",
    "gzAB53E6HEJN",
    "EnH2b3D0kXTd"
   ],
   "include_colab_link": true,
   "name": "Laborator 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
